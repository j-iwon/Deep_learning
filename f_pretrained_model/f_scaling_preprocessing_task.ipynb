{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0218ccc0-9e28-4827-ba0c-e368f70dfc21",
   "metadata": {},
   "source": [
    "### Scaling Preprocessing Task\n",
    "표정 분류  \n",
    "**flow_from_dataframe()을 사용한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905631c3-e0c1-4bf7-ad31-702f74a2b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강사님 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be199e7e-0919-42a2-8c86-12b071ee4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 8060 images belonging to 7 classes.\n",
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "idg = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "original_dir = './datasets/face/original/'\n",
    "test_dir = './datasets/face/test/'\n",
    "\n",
    "original_generator = idg.flow_from_directory(original_dir, \n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                             batch_size=BATCH_SIZE, \n",
    "                                             class_mode='categorical', \n",
    "                                             shuffle=True)\n",
    "\n",
    "test_generator = idg.flow_from_directory(test_dir, \n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                             batch_size=BATCH_SIZE, \n",
    "                                             class_mode='categorical')\n",
    "\n",
    "print(original_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d0dfca-2d99-4d04-924f-8dfa28eee31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'angry',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'happy',\n",
       " 4: 'neutral',\n",
       " 5: 'sad',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name = {v: k for k, v in original_generator.class_indices.items()}\n",
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3169a20c-681f-40f0-a55f-cc3d6ce6af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709 8060\n"
     ]
    }
   ],
   "source": [
    "original_target_names = []\n",
    "test_target_names = []\n",
    "\n",
    "for target in original_generator.classes:\n",
    "    original_target_names.append(target_name[target])\n",
    "\n",
    "for target in test_generator.classes:\n",
    "    test_target_names.append(target_name[target])\n",
    "\n",
    "print(original_target_names.__len__(), test_target_names.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3967cb82-9b0d-4585-b65c-02c4d7bafe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/face/original/angry/angry1.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/face/original/angry/angry10.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/face/original/angry/angry100.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/face/original/angry/angry1000.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/face/original/angry/angry1001.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28704</th>\n",
       "      <td>./datasets/face/original/surprise/surprise995.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28705</th>\n",
       "      <td>./datasets/face/original/surprise/surprise996.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28706</th>\n",
       "      <td>./datasets/face/original/surprise/surprise997.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>./datasets/face/original/surprise/surprise998.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28708</th>\n",
       "      <td>./datasets/face/original/surprise/surprise999.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28709 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_paths target_names  targets\n",
       "0              ./datasets/face/original/angry/angry1.png        angry        0\n",
       "1             ./datasets/face/original/angry/angry10.png        angry        0\n",
       "2            ./datasets/face/original/angry/angry100.png        angry        0\n",
       "3           ./datasets/face/original/angry/angry1000.png        angry        0\n",
       "4           ./datasets/face/original/angry/angry1001.png        angry        0\n",
       "...                                                  ...          ...      ...\n",
       "28704  ./datasets/face/original/surprise/surprise995.png     surprise        6\n",
       "28705  ./datasets/face/original/surprise/surprise996.png     surprise        6\n",
       "28706  ./datasets/face/original/surprise/surprise997.png     surprise        6\n",
       "28707  ./datasets/face/original/surprise/surprise998.png     surprise        6\n",
       "28708  ./datasets/face/original/surprise/surprise999.png     surprise        6\n",
       "\n",
       "[28709 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/face/test/angry/PrivateTest_1013136...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/face/test/angry/PrivateTest_1030447...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/face/test/angry/PrivateTest_1054527...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/face/test/angry/PrivateTest_1059009...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/face/test/angry/PrivateTest_1109992...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>./datasets/face/test/surprise/surprise95.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>./datasets/face/test/surprise/surprise96.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>./datasets/face/test/surprise/surprise97.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>./datasets/face/test/surprise/surprise98.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>./datasets/face/test/surprise/surprise99.png</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8060 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_paths target_names  targets\n",
       "0     ./datasets/face/test/angry/PrivateTest_1013136...        angry        0\n",
       "1     ./datasets/face/test/angry/PrivateTest_1030447...        angry        0\n",
       "2     ./datasets/face/test/angry/PrivateTest_1054527...        angry        0\n",
       "3     ./datasets/face/test/angry/PrivateTest_1059009...        angry        0\n",
       "4     ./datasets/face/test/angry/PrivateTest_1109992...        angry        0\n",
       "...                                                 ...          ...      ...\n",
       "8055       ./datasets/face/test/surprise/surprise95.png     surprise        6\n",
       "8056       ./datasets/face/test/surprise/surprise96.png     surprise        6\n",
       "8057       ./datasets/face/test/surprise/surprise97.png     surprise        6\n",
       "8058       ./datasets/face/test/surprise/surprise98.png     surprise        6\n",
       "8059       ./datasets/face/test/surprise/surprise99.png     surprise        6\n",
       "\n",
       "[8060 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_df = pd.DataFrame({'file_paths': original_generator.filepaths, 'target_names': original_target_names, 'targets': original_generator.classes})\n",
    "original_df.file_paths = original_df.file_paths.apply(lambda file_path: file_path.replace('\\\\', '/'))\n",
    "\n",
    "test_df = pd.DataFrame({'file_paths': test_generator.filepaths, 'target_names': test_target_names, 'targets': test_generator.classes})\n",
    "test_df.file_paths = test_df.file_paths.apply(lambda file_path: file_path.replace('\\\\', '/'))\n",
    "\n",
    "display(original_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7477b954-4395-411e-9958-5fe8f77e116c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/face/original/sad/sad4254.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/face/original/sad/sad4586.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/face/original/neutral/neutral1861.png</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/face/original/angry/angry3888.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/face/original/sad/sad181.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22962</th>\n",
       "      <td>./datasets/face/original/angry/angry3531.png</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22963</th>\n",
       "      <td>./datasets/face/original/sad/sad848.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>./datasets/face/original/happy/happy4192.png</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22965</th>\n",
       "      <td>./datasets/face/original/surprise/surprise1544...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22966</th>\n",
       "      <td>./datasets/face/original/surprise/surprise1828...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22967 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_paths target_names  targets\n",
       "0               ./datasets/face/original/sad/sad4254.png          sad        5\n",
       "1               ./datasets/face/original/sad/sad4586.png          sad        5\n",
       "2       ./datasets/face/original/neutral/neutral1861.png      neutral        4\n",
       "3           ./datasets/face/original/angry/angry3888.png        angry        0\n",
       "4                ./datasets/face/original/sad/sad181.png          sad        5\n",
       "...                                                  ...          ...      ...\n",
       "22962       ./datasets/face/original/angry/angry3531.png        angry        0\n",
       "22963            ./datasets/face/original/sad/sad848.png          sad        5\n",
       "22964       ./datasets/face/original/happy/happy4192.png        happy        3\n",
       "22965  ./datasets/face/original/surprise/surprise1544...     surprise        6\n",
       "22966  ./datasets/face/original/surprise/surprise1828...     surprise        6\n",
       "\n",
       "[22967 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/face/original/happy/happy2734.png</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/face/original/sad/sad891.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/face/original/neutral/neutral2226.png</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/face/original/happy/happy3212.png</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/face/original/neutral/neutral547.png</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>./datasets/face/original/sad/sad3279.png</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>./datasets/face/original/surprise/surprise2269...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>./datasets/face/original/fear/fear2433.png</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>./datasets/face/original/happy/happy1986.png</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>./datasets/face/original/fear/fear3120.png</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_paths target_names  targets\n",
       "0          ./datasets/face/original/happy/happy2734.png        happy        3\n",
       "1               ./datasets/face/original/sad/sad891.png          sad        5\n",
       "2      ./datasets/face/original/neutral/neutral2226.png      neutral        4\n",
       "3          ./datasets/face/original/happy/happy3212.png        happy        3\n",
       "4       ./datasets/face/original/neutral/neutral547.png      neutral        4\n",
       "...                                                 ...          ...      ...\n",
       "5737           ./datasets/face/original/sad/sad3279.png          sad        5\n",
       "5738  ./datasets/face/original/surprise/surprise2269...     surprise        6\n",
       "5739         ./datasets/face/original/fear/fear2433.png         fear        2\n",
       "5740       ./datasets/face/original/happy/happy1986.png        happy        3\n",
       "5741         ./datasets/face/original/fear/fear3120.png         fear        2\n",
       "\n",
       "[5742 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, validation_images, train_targets, validation_targets = \\\n",
    "train_test_split(original_df.file_paths, \n",
    "                 original_df.targets, \n",
    "                 stratify=original_df.targets, \n",
    "                 test_size=0.2, \n",
    "                 random_state=124)\n",
    "\n",
    "train_df = original_df.iloc[train_images.index].reset_index(drop=True)\n",
    "validation_df = original_df.iloc[validation_images.index].reset_index(drop=True)\n",
    "\n",
    "display(train_df)\n",
    "display(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5859c10f-9d8a-4e27-959a-4fd7983584f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os.path\n",
    "\n",
    "base_dir = './datasets/face/'\n",
    "\n",
    "\n",
    "for filepath in train_df.file_paths:\n",
    "    destination = base_dir + 'train/' + filepath[len(base_dir + '/original'):filepath.rindex('/')]\n",
    "    \n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    shutil.copy2(filepath, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3fd032-3e0e-4b7d-9b54-42315037f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os.path\n",
    "\n",
    "base_dir = './datasets/face/'\n",
    "\n",
    "\n",
    "for filepath in validation_df.file_paths:\n",
    "    destination = base_dir + 'validation/' + filepath[len(base_dir + '/original'):filepath.rindex('/')]\n",
    "    \n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    shutil.copy2(filepath, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54dd5a5e-3913-4899-8a82-b76ff3519119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe40lEQVR4nO3dWY+V19Wu4RljDNX3RVOArRhjRCSnkXISJZHSKL8jvy9SpOQkjQ8cReQgckpIxI7TKJjGZYwLqI6qoihwso8Yirb0PvdSTci3P+/7Oh01V631NmtoSc+Y71f+/e9//7tJktRae+V/+g1Ikv7fYVOQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJKKTUGSVF4d9Q+npqZifXJycrC2v78f1z558qSrnrz6av6Ir7xy9L548uTJWH/ttddifX5+frC2srIS105MTMT60tLSkdefPXs2rj127Fisp+OysLAQ19L5ePToUayn90av/ZWvfCXWZ2dnj/R/W8v3xyj148ePD9ZOnDgR11I9HRc6Jl988UWsJzQ3u7W1Fes3b96M9Z///OeDtZ/97GdxLfnXv/515LX0vZCus9ZaO3Xq1GBtZmYmrr169Wqst+YvBUnSf7ApSJKKTUGSVGwKkqRiU5AkFZuCJKnYFCRJZeQ5Bcr7p9zu06dP49pnz56N+jb+61KGm7LKlMPueb4RzUjQax8eHg7WxsfH41rKrqfMPR0z+t9jY2Ox/uDBg8Ha3t5eXEvSMU0zJ63xjETPvAzNCtD9lXLzdL7oeyFdKzR/RLMflOc/ffr0YI3mrnZ3d2O953uBvg+pnu5dWjsKfylIkopNQZJUbAqSpGJTkCQVm4IkqdgUJEll5EgqbffaE0nt2X73ZUtbFhOKph0cHAzWKBJHEUiKpKaYIkUYaftriqwmvduRp0hqqrXGcdie7avpffdEUim6Sddwz//uOde0lo7p3NxcrF+8ePHIa7e3t2M9vXc6H/R9R98bqd4Tc3/OXwqSpGJTkCQVm4IkqdgUJEnFpiBJKjYFSVKxKUiSyshzCpS9Tdl2yt326slKU0a7J49MmeG0dTDNKdC2w5SLT1lp+t+07fDExESsJ3Q+6Jjfv39/sJbmQlrj+YuUm6dZnN57IH1uuv7pvaXXpq2x6TpM11nvuab3trKycqRaa63dunUr1tO93fN91FrfowZexHetvxQkScWmIEkqNgVJUrEpSJKKTUGSVGwKkqRiU5AklZHnFEjKI1Nen3K9Pesp60x5/snJySOv3dvbi/WUKab8N7027UWfXn9jYyOuXVxcjPWUox4bG4tr6ZjSsx7SPviU4abnDqT5DMrM03Mi6HOl80XHlOZK0vxGz3NUetEcA723dJ1euXIlrl1dXY31dD7omND3Hc3TpP99eHgY147CXwqSpGJTkCQVm4IkqdgUJEnFpiBJKjYFSVKxKUiSygubU3jZz0xIUp6ZsueUHx8fHz9SrbW+ZxrQWsojUz2dL5pToJz1/v7+YI1mTnqe29FaPm7pfbXG5zN9bjredB0Syq4ndG+mc0Kfi+Zh0jGjz0TXGd0j6bkeb7/9dlw7MzMT6+vr64O13rksOl+p3vssh9b8pSBJ+g82BUlSsSlIkopNQZJUbAqSpGJTkCSVkSOpFLN6mVtnUz3FGGn7Xaqn2BytpRhiisylLbtb4yhtz7bDFImjaGeStrZurbWVlZVYf/r06ZHrdB1RvLInQkzngz5Xz/bw6X3Ta1MEmK6VtJ62f6f7h85X+t45e/ZsXDs7OxvrKZLai84nfZ/28peCJKnYFCRJxaYgSSo2BUlSsSlIkopNQZJUbAqSpDLynAJlnamevMw5hp75CkJbTFPOenp6erC2uLh45LWt8TbQqU6Zecqup+Py6qv5kqPzcffu3VhPMxT0v+fn52P90aNHg7XeLb9JOl80I7G7uxvr6ZjT1tmPHz+O9SdPnsR6QrM6NCORzjfdP1NTU7Ge0EwKvW/6vkvnpOd4P+cvBUlSsSlIkopNQZJUbAqSpGJTkCQVm4IkqdgUJEll5DkF0rPHN+Vye2YNKMPds3c5Zeppv/iUNx4bG4tr6X3PzMzE+vLy8mBtZ2cnrqXM/e3btwdrFy9ejGsfPHhw5NduLc93UDadpLkTyvN//vnnsd7z3A/a25+ef5HmAei5HVtbW7Gejjk9D4FmIGiWIN27NLtBz/1I91/v3BXNMaTvnZ65q+f8pSBJKjYFSVKxKUiSik1BklRsCpKkYlOQJJWRI6kUTUvbCr9sKeJFkVTaYjpF6ihGSPGwFP2kqB9FUinSmt4bvTZtGf7w4cPB2oULF+La69evx/ra2lqs//CHPxysraysxLXpfbeWtxSnmCFFHOlzpfuL3jdtGZ6u8XPnzsW1ExMTsZ6uJbpGZ2dnY50+V4rirq6uxrUUIU73T89W/631bb1N296Pwl8KkqRiU5AkFZuCJKnYFCRJxaYgSSo2BUlSsSlIksrIcwqUue/ZOptQbj5taUzb0FJ+PM0S0PuiLajT9ta0zTNt/fuHP/wh1tN8Bh0zykIvLS0N1n73u9/FtXQ+Ll++HOspA07biVNu/s6dO4O1g4ODuJZmCWjL8LQ9Nt17PVuhv/fee3HtwsJCrL/++uuDNZpDoK21f/SjH8X6kydPBmsff/zxkdeSl/ldSK9PMw6j8JeCJKnYFCRJxaYgSSo2BUlSsSlIkopNQZJUbAqSpDLynELKMrfGcww9enLz9L4pc5+y0rSXPOWVUxb6/Pnzce39+/djnZ55QOt7pEz+1NRUXHvp0qVYf+utt2I9PT+D9t8/ffp0rC8vLw/W/vSnP8W177//fqzTcwvSTMzh4WFc2/PcAfpcP/3pT2P9W9/61mDtypUrce2vf/3rrvq3v/3twRpd//S9keZh6L6nWQJ63kL6PnwRMxL+UpAkFZuCJKnYFCRJxaYgSSo2BUlSsSlIksrIkVTaJronCtUTwWotR/JSRLE1jkiePHnyyK9NUcAUaaXjTZE5ir2l80X/m+opnkzRZdqCmmLAaatmOtc928NPTk7Gtd///vdjnc7Xb37zm8EaRWnn5uZiPb33H/zgB3Etbfm9uLg4WHvzzTfj2p/85Cexvrq6GuvXrl0brO3t7cW1pCeSSt9n9L2RXp++F0bhLwVJUrEpSJKKTUGSVGwKkqRiU5AkFZuCJKnYFCRJZeQ5BZolSNnanvx3L8oEUz1luCn/TZ97bGxssLa7uxvXUpaZ6mnLcMrM0+ei/53Q+aDrMM05pG3QW8szKa3lY/bVr341rqWZlt/+9rexfvbs2cEazSmkWYHWcmb/jTfeiGvffvvtWL948eJg7c6dO3HtzMxMrKdtuVtr7d133x2s9d4/PfMA9H1H13iqv4hHGPhLQZJUbAqSpGJTkCQVm4IkqdgUJEnFpiBJKjYFSVIZOVDeswd4et5Bay83t0t54v39/Vjf3t4erPXMOLTW2pMnTwZr9L7X1tZi/fHjx7HeM0tA5yu9d5oVSLMArfHnSjltug7pOkufmz7X1tZWrNOMRPrcn332WVxL12l6BsX8/HxcOzs7G+s7OzuDNXq+xfT0dKzT+bxw4cJg7dSpU3EtzZWk/03XEc0B0frkRcx8+UtBklRsCpKkYlOQJBWbgiSp2BQkScWmIEkqNgVJUjl6WP3/kvKxvdlZyoCnzP2xY8fiWpolSJni8fHxuJZy1imPnPLd9L5a69sPntYeP3481nvy/HQ+SHoORXpuQGucD0/ZdTof586di/WPPvoo1i9fvjxYo2uFZj82NzcHa3QN07WQ1tO5pnuXrqX0DIp33nknrv3zn/8c6/S8k6Rnzqe1fB3SMRmFvxQkScWmIEkqNgVJUrEpSJKKTUGSVGwKkqTywrbOpthbfBMQgUxb+7aWI1xpe+rW+HOl2Cm9b9rmOUUgaS1ttby8vBzr6+vrgzWKGZIUz6RjRls1U/Qz6dkuvLV8LVEU8I033oh1ikheu3ZtsPb1r389rqUIZIp+0tbYY2NjsZ6OC0VO6d6lz5W2x6bjfeXKlVi/fft2rPegazx9Z9H32Uj/v/sVJElfGjYFSVKxKUiSik1BklRsCpKkYlOQJBWbgiSpvLCts1PmnrYkpow3bVH9ySefHHktZYLX1tYGa1NTU3Et5agPDw8Haz1b87bGsx1pFoG27qW8/xdffHHk115aWop1ys0fHBwc+X/TdZpy9en/ttbazMxMrH/ve9+L9fT6f/nLX+La8+fPx/qFCxcGa3S8aaYlXSt0vOl80f9OmX3ayvzSpUux/vvf/36wtr+/H9cS+t7o+a4dhb8UJEnFpiBJKjYFSVKxKUiSik1BklRsCpKkYlOQJJWR5xR69mSnvf/n5uZifWtrK9bTHvz0vinrnGYR9vb24lp6JkKqp6x/a5xHptx8yq5vbm7GtfS5e55bQBlvem5H+t8vc66EnivQ89qttfbjH/94sLawsBDXXr9+PdbTPAC9b5pjSHNAPXMGrfH3SvpO6n2GSzrfdA3TbBQ9ZyLVe543Uq/R/QqSpC8Nm4IkqdgUJEnFpiBJKjYFSVKxKUiSysjZQYpIppgUbRu8s7PTVT9z5sxgjSJzi4uLsT4xMXHk90XbX6f4GMVCKZL62WefxXqK8aZaaxx3pWslefToUaxTlDCdb9qKmaKACUUBe7cjT1Hcd955J649ffp0rN+4cSPWE4onP3nyZLBG9+b09HSs92x1TueDvhfSd9rDhw/jWnrfFANOeu695/ylIEkqNgVJUrEpSJKKTUGSVGwKkqRiU5AkFZuCJKm8sDmFlOenrWR7M/nr6+uDNdoumV475eYpT0z1ycnJI/3f1nir5ddeey3W04wF5cPHx8eP/NqE8v7pOqN6z6xNa/mY0jbpvVtrp/dG1wLNA3zjG98YrG1vb8e1dG+nY0bHhM4HzRr0bCNN743ukYTONW0Znj6XW2dLkl4om4IkqdgUJEnFpiBJKjYFSVKxKUiSik1BklRGnlOgTHDKI1PmvmdfdFqf9qFvjd9byitT7p3y4ylTTHl82se+59kA9L7ptVOdPhfNlfTsF0+zG5TxTnV6ZgjNMVB2/fjx44M1ujfptdMxpZkUuhbS/ZM+U2v5WQyt8fdGuo7ptWlWID3/4mU+L6G1fB323Pf1+t2vIEn60rApSJKKTUGSVGwKkqRiU5AkFZuCJKnYFCRJ5YXNKaRMMO1NThlu+t+pfnBwENdSJj+tpzwyZerTa1NO+uTJk7FO8xkJfa6e16bc+9zcXKzTLEE65nQ+6LXTdba7uxvX0jHd2NiI9ZTppxkJms9I1xodk5TXb60vN09rKe+fZnle5rVAeucY0nun741R+EtBklRsCpKkYlOQJBWbgiSp2BQkScWmIEkqI0dSe7Z7pdgnvTZF01JEi7bG7tlOmeJfPfXNzc24lo4Zxd56PldPDJEiwj3bpJOe66i1fK1sbW3FtRTLpqjuBx98MFi7cOFCXDs/Px/rKe5KW0yfOHEi1pPe+56i7OlaoeuIrvF0XHrvzZ5HCfScj+f8pSBJKjYFSVKxKUiSik1BklRsCpKkYlOQJBWbgiSpjDynQNn1lPHu2T6XXpteP22fO4rJycnBGuWRKZO/v78/WKPjTf+bctYpc9+7tW9aT9cCbVlMef90vlIevzXeDjll03uvcfpc6Vr529/+Ftdevnw51tMxo/dF12k65rSWrkM6n2mLd3ptuhZ6to/vmflqrW/GaKTX734FSdKXhk1BklRsCpKkYlOQJBWbgiSp2BQkScWmIEkqI88p0KxAQs9T6JUyx9PT03EtZZ17MsX0rIaUbad97FNuvTXO+588eXKwRjMOdEzS556amoprae9/qqf3TueDPleqLywsxLW0z/2DBw9i/cyZM4O11dXVuDbNIdBrU55/YmIi1tMx652HoXs3XeN0f9GzGug5LQndmz3Pmeh53shz/lKQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJLKyJFUkiKrFMej+BfFrGZmZgZrFJmjWFuq03bJPduNU2SOjglFVtOW4nTMej7XqVOn4tqlpaVYp1hp2uq5d3vrdMxv3LgR19J1Rp/7zTffHKzdu3cvrv3oo49iPUUk6d7tuX9oLcXge2LX9L93d3djfWdnJ9aT3q2z03tPn3lU/lKQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJKKTUGSVEaeU6BsbdoeO80RjPLaJGWpKVP/7NmzWE/vjTLzPdvz0hwCbYdM+fJ0XGhbYDqmKStNx4yy5/S/Dw4Ojvy/NzY2Yv3jjz8erG1vb8e1Fy5ciHW6R9Ix/e53vxvX0rbca2trR35fdEzTVuZ03/deC6lOr/3w4cNY77l36XPT1vVp3obu+1H4S0GSVGwKkqRiU5AkFZuCJKnYFCRJxaYgSSo2BUlSGXlOgXK9T58+Haxtbm7GtZQ3plxvejbA1NRUXEu53vS502wGva/W8jMPKOtM+8HTMUt1mt2gfe7T+aT897Vr12J9a2sr1tPzGj799NO4luYU0twJnY80P9Ea3yPz8/ODNZoVoDmG9957b7B2+/btuJbmZdJ7o2uU7s2e2Slau76+HusJPbeD/nfPcz/oe3qk1+h+BUnSl4ZNQZJUbAqSpGJTkCQVm4IkqdgUJEnFpiBJKiPPKfTMElDemJ47QJn9lOulvckp15v2sd/d3Y1rKc+fXpuyyvTaVE+vT7l3yuSPjY0N1mgWYG5uLtbHx8djfXV1dbBG75uulbS+95kgPfv3p+PdWp5xaK21S5cuDdZu3boV19L5TMd0YmIirqX7Ps1GtdY3V5KOd2v83nrQe0v1nhmH5/ylIEkqNgVJUrEpSJKKTUGSVGwKkqRiU5AklZEjqT0o4kjRzp4IJMVhKeKYop0UiaM6HZeEorQUr0zRNYqz0jFNsdKFhYW4dmlpKdYpfpmuJTrX29vbsb68vBzrSW98uec6pM917ty5wdr9+/fj2rt378Z6unfpGqWYL33utHU2fadQBD/df7SWYqN0f6XtyumYjsJfCpKkYlOQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJLKC5tTSFvJ0tbYlBmmPH/KI1PmlzLDW1tbg7Vnz57FtfS50jGjrHPPNs+t5Qw4HW/63Gk9Zcs3Nzdjnc7n2traYC3lu1vj2Y9Up9emz03r0zGlbbdnZ2dj/dNPPx2s0VxIOt6ttTY9PX3k9zU1NRXrdJ32fCfR+aK5koSuYfpcad6GruFR+EtBklRsCpKkYlOQJBWbgiSp2BQkScWmIEkqNgVJUhl5TiFlflvL2XXKztKsAGWGU2b/5MmTcS3NA1CeOaFjlj7XzMxMXEuzArQX/ePHj2M9oZz13t7eYI2y53S8qb64uDhYo3N99uzZWE+zH3Q+aA6B1m9sbAzW6P6i+yedE7o3b9++HevpWQ5pBqg1PmYTExOxvr+/P1g7ODiIa2kO4WU+T4HWp/dG9/0o/KUgSSo2BUlSsSlIkopNQZJUbAqSpGJTkCSV/8rW2RTvohhVT8yK4l20TW363xQFpO2rE4ooUsyQ1icUBaTPlSKradvf1jhCTJHWc+fODdYoIkzvLW0DTTFDulYoXpkilLdu3Ypr6VpJ/5vOB10LaSv0lZWVuDZFSlvjazydE7oW6HMn9NqkJ9JK1+Eo/KUgSSo2BUlSsSlIkopNQZJUbAqSpGJTkCQVm4IkqYw8p0CzAmkWoWeb5tY4j5xyvbRFbk8emXLUlHtPn2tnZyeupe2rqZ62G5+fn49rSbpW0rbarfHW2HNzc7GergXKj9+7dy/W0/menZ2Na6lOnyudT3rt1dXVWE/bX58+fTqupbmRNKdAsxvpGm2N7+20vuf7rLV8ndHsE92bY2NjR17fM5/0nL8UJEnFpiBJKjYFSVKxKUiSik1BklRsCpKkYlOQJJX/yvMUaD93yitTpjhlhg8PD4+8trXWlpeXB2vr6+tx7e7ubqynTDHNT1CGm45Zen06JvS/E5rdoOw5nc/t7e3B2qlTp+Jayqanz03ZdLoH6HOl7PrS0lJc+53vfCfWP/zww8Ha1tZWXEv796dnUNDxpvkmOqY9swQPHz6M9aT3eQo9z7DonQlrzV8KkqT/YFOQJBWbgiSp2BQkScWmIEkqNgVJUhk5W0gxq1SneGRvhKtn62yKcKXXprUUuUvxzJ5tt1vjyF06JxMTE3EtRQHTeoo4nj17NtYpLruxsTFYo5ghbWm8sLAwWLt//35cS8f0wYMHsX7u3LnBGkUYU6y6tda+9rWvDdZu3rwZ15IUpaUtoin6TNdCiidTXPzvf/97rKfvLIrYU53u/bSeos2j8JeCJKnYFCRJxaYgSSo2BUlSsSlIkopNQZJUbAqSpDLynALNGlD9ZUrzAPv7+3EtzUikrDRlgin3nmYJKIO9uLgY6ynX3lo+LnQuKWedZhFodoPOB33uNDtC7/utt96K9TRrQNfZjRs3Yp1mCdLnonNN8zQzMzODNdpufGdnJ9bT+aRzvbm5Ges0q5Ok7cJba+327dux3jOnQPMZNNOSvhtohmgU/lKQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJKKTUGSVEaeU3iZXuaMA+X9KV+e1tN+7yRl9mdnZ+Pa6enpWKfnSKQsNc0C0HMJUn6cMtjz8/OxvrS0dOT1dEzPnDkT62nuhOYMaKbl3r17sZ6emUDnugdl7tfX12M9ZfLpGqY5BJpzOHbs2GCNnpdA8zTptXvnFNJrt5bPd8/sxnP+UpAkFZuCJKnYFCRJxaYgSSo2BUlSsSlIkopNQZJURg7aUya4Z9aAZglIz57tPXlkQq+dPvfu7m5c++TJk1inz/36668P1mgWYGFhIdbT/v2UqR8fH4/1ycnJWD99+vSRXzvNArSWM+D0zAJy6dKlWE/zALSHPh3zubm5wdrx48fjWrrO0jHb2NiIa+n+Sc8jaS0/E4Gep0DfSWnWgK5Rmpeh75w08+KcgiTphbIpSJKKTUGSVGwKkqRiU5AkFZuCJKmMHEl9mdtb93qZ760n7toTh6VIKsUnV1ZWYj3F4igy9+DBg1hPEUiKT1JMkeJ6aTtzitpubW3FetpSnM7X2tparH/zm9+M9YsXLw7WaBvotOV3azlCeffu3biWopubm5uDtb29vbh2ZmYm1ilq+8tf/nKwluKqrfVdZ3T/UMyXjmmKndJ3zij8pSBJKjYFSVKxKUiSik1BklRsCpKkYlOQJBWbgiSpjDyn8L8VzTBQrjfl6ilvTFv/vvLKcE+mOQT632lr39ZaO3Xq1GCNctK0TfT+/v5gjY53yn+3lo9Za61tb28P1u7cuRPXLi8vx3o65pS5p63O79+/H+tTU1ODtbT1dWucuU91WptmN1rLn5vuzYcPH8b6u+++G+t//OMfj/S+WuP7Lx2XdK5obWs8f/Ho0aPBGt0fo/CXgiSp2BQkScWmIEkqNgVJUrEpSJKKTUGSVGwKkqTypZ9TID1zDGlf89Y4M5zyyjQrQO+b1qdZAnqmAc1fpOz64eFhXJv29h9F+tw0S0D58fS8BZqvoLkReh7DjRs3Bmv0nAi6TtMzE9J10hpfZ2nO5/33349rP/zww1j/5JNPYj2db7o36Xyl2RCacSB0j6T7j+aXRuEvBUlSsSlIkopNQZJUbAqSpGJTkCQVm4Ikqfx/H0klKZJKcbyebaIpWvbaa6/FOsXaUgyR4pFp2+3W8nGh933ixIlYJ+lznz17Nq6lqO3ExMRgjd43xV0///zzWJ+ZmRms0bWysLAQ6+k6pW3SP/jgg1i/evXqYO369etxLd1fPeh8UT3FrlMMtzWOk9O23ulaomt4FP5SkCQVm4IkqdgUJEnFpiBJKjYFSVKxKUiSik1BklScUwApK03b71JmOOWRaftd2qr54OAg1tP22LRdMs0apNw7ve80C9Aaf640Y3H+/Pm4dmVlJdanp6cHa5SppzkFOqYPHjx4aa+dtta+d+9eXPurX/0q1v/5z38O1mi+gvL8VE/Hhf53mgtpLR9Tmu2g/03fGz2zU6Pwl4IkqdgUJEnFpiBJKjYFSVKxKUiSik1BklRsCpKk4pzC/6C07/re3l5cS9l0mqFIGe/x8fG4lvZ7T7MEOzs7cS09g4JmKGZnZwdrk5OTcS3NQKQMOGXT6XzQ8xRSLp72/qfsepqB+MUvfhHX3rhxI9bTddo7h0DHNM3E0LVAz6BI1wq9L7p36XOne2RsbCyuHYW/FCRJxaYgSSo2BUlSsSlIkopNQZJUbAqSpGJTkCQV5xRAyhxT/pvyyqlOmXl6LgE9j4HmARLaDz7NWNBe8dvb27FOnzu9fnqGRGutzc3NxfrNmzcHa5Qtp2OWZlZay9cKzUikZxq0lmcR/vGPf8S1lLmn853Q/UPXcHo2R5pnGeW106wOzQrQ+eqZ36D7fhT+UpAkFZuCJKnYFCRJxaYgSSo2BUlSsSlIkoqRVECx06QnWkZraWttitTNzMwM1ihGODU1FeuHh4eDNYrapi2iW+uLQD569CiupdhoQseE/jfFL1PM8erVq3HtX//611i/d+/eYK03ctoTfaZ7j7Z4T/FMOl8UG03XCsWmd3d3Y53WJ3S+RuEvBUlSsSlIkopNQZJUbAqSpGJTkCQVm4IkqdgUJEll5EAs5eYlSf/7+UtBklRsCpKkYlOQJBWbgiSp2BQkScWmIEkqNgVJUrEpSJKKTUGSVP4Pllt+0MAynasAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(train_df.file_paths.iloc[22962]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca60882-00f9-42e3-9dfb-dc394f066fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22967 validated image filenames belonging to 7 classes.\n",
      "Found 5742 validated image filenames belonging to 7 classes.\n",
      "Found 8060 validated image filenames belonging to 7 classes.\n",
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_generator = ImageDataGenerator(horizontal_flip=True, preprocessing_function=preprocess_input)\n",
    "validation_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_flow = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='file_paths',\n",
    "    y_col='target_names',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_flow = validation_generator.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    x_col='file_paths',\n",
    "    y_col='target_names',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_flow = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='file_paths',\n",
    "    y_col='target_names',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(train_flow.class_indices)\n",
    "print(validation_flow.class_indices)\n",
    "print(test_flow.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef0cca43-729a-41ed-b684-0a51842326b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    if model_name == 'vgg16':\n",
    "        model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'resnet50': # ResNet50, 74.9% ; ResNet50V2, 76.0%\n",
    "        model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'xception': # Inception을 기초로 한 모델\n",
    "        model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "    x = model.output\n",
    "\n",
    "    # 분류기\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    output = Dense(7, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2724637c-edaf-4c20-8fd2-8fcc8c8b2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model = create_model(model_name='xception', verbose=False)\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ebc1f0-7afb-455b-a906-70560a6d3678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513eef7b-f6e1-4a31-a7c1-6c8092336d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a9dee1-bead-4b55-94db-aeae200ebff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/359\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:41\u001b[0m 14s/step - acc: 0.1677 - loss: 1.9961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_flow, \n\u001b[0;32m      4\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      5\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS, \n\u001b[0;32m      6\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mvalidation_flow,\n\u001b[0;32m      7\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[mcp_cb, rlr_cb, ely_cb])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_flow, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=N_EPOCHS, \n",
    "                    validation_data=validation_flow,\n",
    "                    callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840df177-d8f8-42a7-bce5-271c69fe0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6af65-157b-4307-991e-ec489802b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209adc7f-a7f0-4cf7-9d02-815b76a9a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba603ef1-8e0d-4c01-bcc3-4bbfc4dba380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "train_root = './datasets/face/original/'\n",
    "test_root = './datasets/face/test/'\n",
    "\n",
    "directories = glob(os.path.join(train_root, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f11b69-64db-4d98-84aa-98aa8f529960",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_names = []\n",
    "\n",
    "for directory in directories:\n",
    "    directory_names.append(directory[directory.rindex('\\\\') + 1:])\n",
    "\n",
    "print(directory_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ceb752-5b6c-4e58-889f-ee2e5ef15778",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in directory_names:\n",
    "    for i, file_name in enumerate(os.listdir(os.path.join(train_root, name))):\n",
    "        old_file = os.path.join(train_root + name + '/', file_name)\n",
    "        new_file = os.path.join(train_root + name + '/', name + str(i + 1) + '.png')\n",
    "\n",
    "        os.rename(old_file, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d083ef-5116-4ba6-8c2b-667ca38a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in directory_names:\n",
    "    for i, file_name in enumerate(os.listdir(os.path.join(test_root, name))):\n",
    "        old_file = os.path.join(test_root + name + '/', file_name)\n",
    "        new_file = os.path.join(test_root + name + '/', name + str(i + 1) + '.png')\n",
    "\n",
    "        os.rename(old_file, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5acc283-be65-490f-aade-4cf95ea0ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ImageDataGenerator 이미지 전처리기를 통해 0과 1로 픽셀값을 정규화한다.\n",
    "idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = idg.flow_from_directory(train_root, target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "test_generator = idg.flow_from_directory(test_root, target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521808f1-c955-41c1-bb3a-ea8ac5c85d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.class_indices의 키값과 벨류값으로 target_name에 딕셔너리 형태로 인덱스 번호와 인덱스값으로 만들어준다.\n",
    "trian_target_name = {v: k for k, v in train_generator.class_indices.items()}\n",
    "test_target_name = {v: k for k, v in test_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff51cc-238b-429e-9205-6464d3134c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_name을 리스트 형태로 만들어준다.\n",
    "train_target_names = []\n",
    "for target in train_generator.classes:\n",
    "    train_target_names.append(trian_target_name[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eeb2db-7643-44a1-8043-9faa278c45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_names = []\n",
    "for target in test_generator.classes:\n",
    "    test_target_names.append(test_target_name[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbeec9-29ce-49a1-920f-7523f3682bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame({'file_paths':train_generator.filepaths, 'target_names': train_target_names, 'targets': train_generator.classes})\n",
    "train_df.file_paths = train_df.file_paths.apply(lambda x: x.replace('\\\\', '/'))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855c27d-c398-47d3-8c05-b78ecbf1504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.DataFrame({'file_paths':test_generator.filepaths, 'target_names': test_target_names, 'targets': test_generator.classes})\n",
    "test_df.file_paths = test_df.file_paths.apply(lambda x: x.replace('\\\\', '/'))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c402bc-ef1e-498b-9daf-66dc0080ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = \\\n",
    "train_test_split(train_df.file_paths, train_df.targets, stratify=train_df.targets, test_size=0.2, random_state=124)\n",
    "\n",
    "X_test = test_df.file_paths\n",
    "y_test = test_df.targets\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_validation.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea701920-440e-41a4-873f-cf8de62618db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 데이터프레임에서 각 images에 맞는 인덱스 번호로 다시 인덱스 번호를 설정해준다.\n",
    "train_df2 = train_df.iloc[X_train.index].reset_index(drop=True)\n",
    "validation_df = train_df.iloc[X_validation.index].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f64f8-8a9d-4deb-be9e-3cda2b82ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import albumentations as A\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 이미지 스케일 전처리 함수 + argumentarion이 포함된\n",
    "def preprocessing_scaling_for_train(image, mode='tf'):\n",
    "    aug = A.HorizontalFlip(p=0.5)\n",
    "    image = aug(image=image)['image']\n",
    "    \n",
    "    if mode == 'tf': # -1 ~ 1 scale\n",
    "        image = image / 127.5\n",
    "        image -= 1.\n",
    "    \n",
    "    elif mode == 'torch': # z-score scale\n",
    "        image = image / 255.\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        \n",
    "        image[:, :, 0] = (image[:, :, 0] - mean[0])/std[0]\n",
    "        image[:, :, 1] = (image[:, :, 1] - mean[1])/std[1]\n",
    "        image[:, :, 2] = (image[:, :, 2] - mean[2])/std[2]\n",
    "        \n",
    "    return image\n",
    "    \n",
    "# 이미지 스케일 전처리 함수\n",
    "def preprocessing_scaling(image, mode='tf'):\n",
    "    if mode == 'tf': # -1 ~ 1 scale\n",
    "        image = image / 127.5\n",
    "        image -= 1.\n",
    "    \n",
    "    elif mode == 'torch': # z-score scale\n",
    "        image = image / 255.\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        \n",
    "        image[:, :, 0] = (image[:, :, 0] - mean[0])/std[0]\n",
    "        image[:, :, 1] = (image[:, :, 1] - mean[1])/std[1]\n",
    "        image[:, :, 2] = (image[:, :, 2] - mean[2])/std[2]\n",
    "        \n",
    "    return image\n",
    "\n",
    "# ImageDataGenerator 생성기를 호출한다.\n",
    "# train 에만 aug가 포함된 scaling을 넣어준다.\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling_for_train)\n",
    "validation_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling)\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling)\n",
    "\n",
    "# flow_from_dataframe 메소드를 사용하여 데이터를 불러온다.\n",
    "train_flow = train_generator.flow_from_dataframe(dataframe=train_df, \n",
    "                                                 x_col='file_paths', \n",
    "                                                 y_col='target_names',\n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "validation_flow = validation_generator.flow_from_dataframe(dataframe=validation_df, \n",
    "                                                 x_col='file_paths', \n",
    "                                                 y_col='target_names',\n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_flow = test_generator.flow_from_dataframe(dataframe=test_df, \n",
    "                                                 x_col='file_paths', \n",
    "                                                 y_col='target_names',\n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "print(train_flow.class_indices)\n",
    "print(validation_flow.class_indices)\n",
    "print(test_flow.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f251a5b-fa64-4fc6-b1b7-6280f7e5ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(train_df.file_paths.iloc[101]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d1622-1874-4df6-97a3-eef35b3bf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image_tf = preprocessing_scaling(image, mode='tf')\n",
    "scaled_image_torch = preprocessing_scaling(image, mode='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174e552-0fe4-4294-943a-0e88a96c23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pixel_histogram(image):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    titles = ['Red', 'Green', 'Blue']\n",
    "    for i in range(3):\n",
    "        axs[i].hist(image[:, :, i].flatten(), bins=100, alpha=0.5)\n",
    "        title_str = titles[i]\n",
    "        axs[i].set(title=title_str)\n",
    "\n",
    "show_pixel_histogram(scaled_image_tf)\n",
    "show_pixel_histogram(scaled_image_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b121e-a2a0-4b7f-88e5-d47fb840cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    if model_name == 'vgg16':\n",
    "        model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'resnet50': # ResNet50, 74.9% ; ResNet50V2, 76.0%\n",
    "        model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'xception': # Inception을 기초로 한 모델\n",
    "        model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "    x = model.output\n",
    "\n",
    "    # 분류기\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    output = Dense(7, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172aee6-611b-48cc-b2fc-519c191def47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model = create_model(model_name='xception', verbose=True)\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec14c3-c212-4cea-9f51-5049c4df1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd2ecd-397e-46b4-8957-c90467ec4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0fc1f-3a6d-4f4d-8cc0-0221dcd8a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_flow, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=N_EPOCHS, \n",
    "                    validation_data=validation_flow, \n",
    "                    callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fecd6-1411-40cd-9e10-7a059c8a30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c6fe2-fba7-4243-9ddd-e341a9c3c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
