{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c730943a-779b-4f00-afc3-725cb802f7b6",
   "metadata": {},
   "source": [
    "### **Callback API**\n",
    "- 모델이 학습 중에 충돌이 발생하거나 네트워크가 끊기면, 모든 훈련 시간이 낭비될 수 있고,\n",
    "  과적합을 방지하기 위해 훈련을 중간에 중지해야 할 수도 있다.\n",
    "- 모델이 학습을 시작하면 학습이 완료될 때까지 아무런 제어를 하지 못하게 되고,\n",
    "  신경망 훈련을 완료하는 데에는 몇 시간 또는 며칠이 걸릴 수 있기 때문에 모델을 모니터링하고 제어할 수 있는 기능이 필요하다.\n",
    "- 훈련시(fit()) Callback API를 등록시키면 반복 내에서 특정 이벤트 발생마다 등록된 callback이 호출되어 수행된다.\n",
    "\n",
    "**ModelCheckpoint(filepath, monitor='val_loss', valbose=0, save_best_only=False, save_weight_only=False, mode='auto')**\n",
    "- 특정 조건에 따라서 모델 또는 가중치를 파일로 저장한다.\n",
    "- filepath: \" weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5 \"와 같이 모델의 체크포인트를 저장한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다\n",
    "- save_best_only: 가장 좋은 성능을 나타내는 모델을 저장할지에 대한 여부\n",
    "- save_weight_only: weights만 저장할지에 대한 여부\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>\n",
    "\n",
    "**ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, vervose=0, mode='auto', min_lr=0)**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습률을 동적으로 감소시킨다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- factor: 학습률을 감소시킬 비율, 새로운 학습률 = 기존 학습률 * factor\n",
    "- patience: 학습률을 줄이기 전에 monitor할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>\n",
    "\n",
    "**EarlyStopping(monitor='val_loss', patience=0, vervose=0, mode='auto')**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습을 조기에 중단한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- patience: Early Stopping을 적용하기 전에 monitor할 반복 횟수.\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ffa4d-a7b1-4b69-aacd-3ee0b7df4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모니터에 뭘 넣는지에 따라 모드가 날라진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0249c425-30a8-4ec6-ac71-000ff66a3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38cc421-85d5-4e1e-848c-81fe8f6c45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd93bc8-d6fb-4dae-8d31-2007449d5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98947770-2a6e-4b57-aa3c-e17eea9ec307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 6A3C-E039\n",
      "\n",
      " E:\\kdt_0900_pjw\\ai\\deep_learning\\c_tensorflow 디렉터리\n",
      "\n",
      "2024-05-28 화  오전 09:48    <DIR>          .\n",
      "2024-05-27 월  오후 01:51    <DIR>          ..\n",
      "2024-05-28 화  오전 09:24    <DIR>          .ipynb_checkpoints\n",
      "2024-05-27 월  오후 04:29           676,428 a_tensorflow_g1.ipynb\n",
      "2024-05-27 월  오후 03:57            90,097 a_tensorflow_T.ipynb\n",
      "2024-05-27 월  오후 05:36             9,764 b_keras_g1.ipynb\n",
      "2024-05-27 월  오후 05:36           160,190 b_keras_T.ipynb\n",
      "2024-05-28 화  오전 09:23           162,362 b_keras_task.ipynb\n",
      "2024-05-27 월  오후 01:25    <DIR>          callback_files\n",
      "2024-05-28 화  오전 09:48             7,182 c_callback.ipynb\n",
      "2024-05-27 월  오후 03:26    <DIR>          images\n",
      "               6개 파일           1,106,023 바이트\n",
      "               5개 디렉터리  488,067,239,936 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a4b1c7-b167-42c4-8466-3324c283391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 6A3C-E039\n",
      "\n",
      " E:\\kdt_0900_pjw\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-27 월  오후 01:25    <DIR>          .\n",
      "2024-05-28 화  오전 09:48    <DIR>          ..\n",
      "               0개 파일                   0 바이트\n",
      "               2개 디렉터리  488,067,239,936 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd240e-9ee8-4dbd-b1e3-23fe027d65fd",
   "metadata": {},
   "source": [
    "### ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a358c-e67f-4542-b5c5-51492b7b2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# weight 저장하기\n",
    "# 생성자를 연다. ModelCheckpoint\n",
    "# 꼭 담아줘야한다.\n",
    "# 담은 후에 fit에 넣어준다.\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# model 저장하기\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "#     monitor='val_loss',\n",
    "#     # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# callback 파라미터 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e6b6c-ecdc-4e64-9f8f-b51b0bbc56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_best_only 를 False로 주면 전부 다 저장 True를 주면 가장 좋은 성능이라 판단될 경우만 저장\n",
    "# save_weight_only 를 False 로 주면 모델을 저장\n",
    "\n",
    "# weight를 파일로 내보내는 이유: 모델을 내보내면 그걸 그대로 프리딕트 하겠다는 뜻. 웨이트를 내보내면 거기서부터 시작.\n",
    "# 그걸 가져다가 본인들의 이미지로 훈련시키겠다는 뜻. 사용하는 용도가 더 많아짐.\n",
    "# 모델의 층까지 동일하게 쓰고싶다 = keras 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a7e05-aa55-4ba2-86b2-03a64e378322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 파일 확인\n",
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7f7b6-12b0-4642-a75a-0b829a89a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62fb3f-5bd5-4ef4-b643-a80779267c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_model 초기화\n",
    "model = create_model()\n",
    "\n",
    "# weights 불러오기\n",
    "# model.load_weights(경로)\n",
    "model.load_weights('./callback_files/weights.020-0.3282-0.9295.weights.h5')\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# test 확인\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ca7c2-c748-4504-99c7-8f47f36a0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55532185-e974-40b5-aa60-6109655a6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# model 불러오기\n",
    "# model = load_model(경로)\n",
    "model = load_model('./callback_files/model.020-0.3350-0.9287.model.keras')\n",
    "\n",
    "# test 확인\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d0bf4-d36d-410d-a836-d5cc3d1ae81d",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e76582-549f-4026-a0b2-f482f9e65431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# 생성자를 연다. ReduceLROnPlateau\n",
    "# 꼭 담아줘야한다. 담은 후에 fit에 넣어준다.\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback 파라미터에 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61537987-b7b9-46df-98ca-084d4ec639d9",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6744d24-1c21-4b3b-ab5b-2ee7c1122b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc']\n",
    "\n",
    "# 생성자를 연다. EarlyStopping\n",
    "# 꼭 담아줘야한다. 담은 후에 fit에 넣어준다.\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback 파라미터에 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe39486-9cdb-4a3b-941e-8e709bc2eae0",
   "metadata": {},
   "source": [
    "### 세개 다 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ac3d7-3d8e-4811-89b7-c538fe4ac76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
