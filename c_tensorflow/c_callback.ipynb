{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c730943a-779b-4f00-afc3-725cb802f7b6",
   "metadata": {},
   "source": [
    "### **Callback API**\n",
    "- 모델이 학습 중에 충돌이 발생하거나 네트워크가 끊기면, 모든 훈련 시간이 낭비될 수 있고,\n",
    "  과적합을 방지하기 위해 훈련을 중간에 중지해야 할 수도 있다.\n",
    "- 모델이 학습을 시작하면 학습이 완료될 때까지 아무런 제어를 하지 못하게 되고,\n",
    "  신경망 훈련을 완료하는 데에는 몇 시간 또는 며칠이 걸릴 수 있기 때문에 모델을 모니터링하고 제어할 수 있는 기능이 필요하다.\n",
    "- 훈련시(fit()) Callback API를 등록시키면 반복 내에서 특정 이벤트 발생마다 등록된 callback이 호출되어 수행된다.\n",
    "\n",
    "**ModelCheckpoint(filepath, monitor='val_loss', valbose=0, save_best_only=False, save_weight_only=False, mode='auto')**\n",
    "- 특정 조건에 따라서 모델 또는 가중치를 파일로 저장한다.\n",
    "- filepath: \" weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5 \"와 같이 모델의 체크포인트를 저장한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다\n",
    "- save_best_only: 가장 좋은 성능을 나타내는 모델을 저장할지에 대한 여부\n",
    "- save_weight_only: weights만 저장할지에 대한 여부\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>\n",
    "\n",
    "**ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, vervose=0, mode='auto', min_lr=0)**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습률을 동적으로 감소시킨다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- factor: 학습률을 감소시킬 비율, 새로운 학습률 = 기존 학습률 * factor\n",
    "- patience: 학습률을 줄이기 전에 monitor할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>\n",
    "\n",
    "**EarlyStopping(monitor='val_loss', patience=0, vervose=0, mode='auto')**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습을 조기에 중단한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- patience: Early Stopping을 적용하기 전에 monitor할 반복 횟수.\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  <sub>monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890ffa4d-a7b1-4b69-aacd-3ee0b7df4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모니터에 뭘 넣는지에 따라 모드가 날라진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0249c425-30a8-4ec6-ac71-000ff66a3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38cc421-85d5-4e1e-848c-81fe8f6c45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd93bc8-d6fb-4dae-8d31-2007449d5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98947770-2a6e-4b57-aa3c-e17eea9ec307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 6A3C-E039\n",
      "\n",
      " E:\\kdt_0900_pjw\\ai\\deep_learning\\c_tensorflow 디렉터리\n",
      "\n",
      "2024-05-28 화  오후 05:13    <DIR>          .\n",
      "2024-05-28 화  오전 11:29    <DIR>          ..\n",
      "2024-05-28 화  오후 04:53    <DIR>          .ipynb_checkpoints\n",
      "2024-05-28 화  오후 05:13            92,902 a_tensorflow.ipynb\n",
      "2024-05-28 화  오후 05:13            33,450 b_keras.ipynb\n",
      "2024-05-28 화  오전 11:22           162,362 b_keras_task.ipynb\n",
      "2024-05-28 화  오전 11:09    <DIR>          callback_files\n",
      "2024-05-28 화  오전 11:22            17,378 c_callback.ipynb\n",
      "2024-05-28 화  오후 04:26            14,985 c_callback_task.ipynb\n",
      "2024-05-27 월  오후 03:26    <DIR>          images\n",
      "2024-05-28 화  오후 04:53                72 Untitled.ipynb\n",
      "               6개 파일             321,149 바이트\n",
      "               5개 디렉터리  488,045,563,904 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a4b1c7-b167-42c4-8466-3324c283391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 6A3C-E039\n",
      "\n",
      " E:\\kdt_0900_pjw\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-28 화  오전 11:09    <DIR>          .\n",
      "2024-05-28 화  오후 05:13    <DIR>          ..\n",
      "2024-05-28 화  오전 11:09           739,600 weights.001-0.1798-0.9015.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.002-0.1453-0.9571.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.003-0.1256-0.9682.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.004-0.1084-0.9741.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.005-0.0909-0.9791.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.006-0.1047-0.9825.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.007-0.0865-0.9856.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.008-0.0943-0.9868.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.009-0.1112-0.9900.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.010-0.0804-0.9954.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.011-0.0779-0.9970.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.012-0.0784-0.9975.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.013-0.0778-0.9977.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.014-0.0775-0.9984.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.015-0.0776-0.9985.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.016-0.0776-0.9984.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.017-0.0776-0.9985.weights.h5\n",
      "              17개 파일          12,573,200 바이트\n",
      "               2개 디렉터리  488,045,563,904 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd240e-9ee8-4dbd-b1e3-23fe027d65fd",
   "metadata": {},
   "source": [
    "### ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5a358c-e67f-4542-b5c5-51492b7b2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - acc: 0.7298 - loss: 0.7630 - val_acc: 0.8453 - val_loss: 0.4312\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8571 - loss: 0.3998 - val_acc: 0.8612 - val_loss: 0.3702\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8734 - loss: 0.3514 - val_acc: 0.8682 - val_loss: 0.3616\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8833 - loss: 0.3207 - val_acc: 0.8705 - val_loss: 0.3544\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8896 - loss: 0.3042 - val_acc: 0.8692 - val_loss: 0.3467\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8873 - loss: 0.2958 - val_acc: 0.8798 - val_loss: 0.3288\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8976 - loss: 0.2796 - val_acc: 0.8716 - val_loss: 0.3434\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9002 - loss: 0.2675 - val_acc: 0.8842 - val_loss: 0.3169\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9073 - loss: 0.2499 - val_acc: 0.8847 - val_loss: 0.3167\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9075 - loss: 0.2490 - val_acc: 0.8878 - val_loss: 0.3125\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9095 - loss: 0.2399 - val_acc: 0.8798 - val_loss: 0.3458\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9099 - loss: 0.2305 - val_acc: 0.8863 - val_loss: 0.3244\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9186 - loss: 0.2173 - val_acc: 0.8855 - val_loss: 0.3161\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9177 - loss: 0.2196 - val_acc: 0.8857 - val_loss: 0.3286\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9209 - loss: 0.2079 - val_acc: 0.8845 - val_loss: 0.3306\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9226 - loss: 0.2057 - val_acc: 0.8904 - val_loss: 0.3117\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9234 - loss: 0.2013 - val_acc: 0.8881 - val_loss: 0.3395\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9280 - loss: 0.1914 - val_acc: 0.8867 - val_loss: 0.3313\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9293 - loss: 0.1890 - val_acc: 0.8870 - val_loss: 0.3236\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9315 - loss: 0.1816 - val_acc: 0.8898 - val_loss: 0.3417\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# weight 저장하기\n",
    "# 생성자를 연다. ModelCheckpoint\n",
    "# 꼭 담아줘야한다.\n",
    "# 담은 후에 fit에 넣어준다.\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# model 저장하기\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "#     monitor='val_loss',\n",
    "#     # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# callback 파라미터 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23e6b6c-ecdc-4e64-9f8f-b51b0bbc56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_best_only 를 False로 주면 전부 다 저장 True를 주면 가장 좋은 성능이라 판단될 경우만 저장\n",
    "# save_weight_only 를 False 로 주면 모델을 저장\n",
    "\n",
    "# weight를 파일로 내보내는 이유: 모델을 내보내면 그걸 그대로 프리딕트 하겠다는 뜻. 웨이트를 내보내면 거기서부터 시작.\n",
    "# 그걸 가져다가 본인들의 이미지로 훈련시키겠다는 뜻. 사용하는 용도가 더 많아짐.\n",
    "# 모델의 층까지 동일하게 쓰고싶다 = keras 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760a7e05-aa55-4ba2-86b2-03a64e378322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 6A3C-E039\n",
      "\n",
      " E:\\kdt_0900_pjw\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-28 화  오후 05:26    <DIR>          .\n",
      "2024-05-28 화  오후 05:25    <DIR>          ..\n",
      "2024-05-28 화  오전 11:09           739,600 weights.001-0.1798-0.9015.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.001-0.4312-0.8026.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.002-0.1453-0.9571.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.002-0.3702-0.8593.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.003-0.1256-0.9682.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.003-0.3616-0.8725.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.004-0.1084-0.9741.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.004-0.3544-0.8816.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.005-0.0909-0.9791.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.005-0.3467-0.8881.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.006-0.1047-0.9825.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.006-0.3288-0.8906.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.007-0.0865-0.9856.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.007-0.3434-0.8977.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.008-0.0943-0.9868.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.008-0.3169-0.8994.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.009-0.1112-0.9900.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.009-0.3167-0.9047.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.010-0.0804-0.9954.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.010-0.3125-0.9067.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.011-0.0779-0.9970.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.011-0.3458-0.9106.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.012-0.0784-0.9975.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.012-0.3244-0.9110.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.013-0.0778-0.9977.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.013-0.3161-0.9163.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.014-0.0775-0.9984.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.014-0.3286-0.9185.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.015-0.0776-0.9985.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.015-0.3306-0.9190.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.016-0.0776-0.9984.weights.h5\n",
      "2024-05-28 화  오후 05:25           739,600 weights.016-0.3117-0.9222.weights.h5\n",
      "2024-05-28 화  오전 11:09           739,600 weights.017-0.0776-0.9985.weights.h5\n",
      "2024-05-28 화  오후 05:26           739,600 weights.017-0.3395-0.9232.weights.h5\n",
      "2024-05-28 화  오후 05:26           739,600 weights.018-0.3313-0.9260.weights.h5\n",
      "2024-05-28 화  오후 05:26           739,600 weights.019-0.3236-0.9290.weights.h5\n",
      "2024-05-28 화  오후 05:26           739,600 weights.020-0.3417-0.9297.weights.h5\n",
      "              37개 파일          27,365,200 바이트\n",
      "               2개 디렉터리  488,030,728,192 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "# 저장된 파일 확인\n",
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda7f7b6-12b0-4642-a75a-0b829a89a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.8817 - loss: 0.3720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36918577551841736, 0.8828999996185303]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b62fb3f-5bd5-4ef4-b643-a80779267c3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = './callback_files/weights.020-0.3282-0.9295.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# weights 불러오기\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model.load_weights(경로)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./callback_files/weights.020-0.3282-0.9295.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# compile\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = './callback_files/weights.020-0.3282-0.9295.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# create_model 초기화\n",
    "model = create_model()\n",
    "\n",
    "# weights 불러오기\n",
    "# model.load_weights(경로)\n",
    "model.load_weights('./callback_files/weights.020-0.3282-0.9295.weights.h5')\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# test 확인\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ca7c2-c748-4504-99c7-8f47f36a0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55532185-e974-40b5-aa60-6109655a6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# model 불러오기\n",
    "# model = load_model(경로)\n",
    "model = load_model('./callback_files/model.020-0.3350-0.9287.model.keras')\n",
    "\n",
    "# test 확인\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d0bf4-d36d-410d-a836-d5cc3d1ae81d",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e76582-549f-4026-a0b2-f482f9e65431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# 생성자를 연다. ReduceLROnPlateau\n",
    "# 꼭 담아줘야한다. 담은 후에 fit에 넣어준다.\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback 파라미터에 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61537987-b7b9-46df-98ca-084d4ec639d9",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6744d24-1c21-4b3b-ab5b-2ee7c1122b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc']\n",
    "\n",
    "# 생성자를 연다. EarlyStopping\n",
    "# 꼭 담아줘야한다. 담은 후에 fit에 넣어준다.\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback 파라미터에 전달\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe39486-9cdb-4a3b-941e-8e709bc2eae0",
   "metadata": {},
   "source": [
    "### 세개 다 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ac3d7-3d8e-4811-89b7-c538fe4ac76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
