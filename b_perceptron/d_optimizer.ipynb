{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8eba17-f31c-4cbc-be45-95bc40e3085d",
   "metadata": {},
   "source": [
    "### **Optimizer, 최적화**\n",
    "- 최적의 경사 하강법을 적용하기 위해 필요하며, 최소값을 찾아가는 방법들을 의미한다.\n",
    "- loss를 줄이는 방향으로 최소 loss를 보다 빠르고 안정적으로 수렴할 수 있어야한다.\n",
    "\n",
    "<img src=\"./images/optimizer.png\" width=\"650px\"  style=\"margin-left: 10px\">\n",
    "\n",
    "#### **Momentum**\n",
    "- 가중치를 계속 업데이트 할 때마다 이전의 값을 일정 수준 반영시키면서 새로운 가중치로 업데이트한다.\n",
    "- 지역 최소값에서 벗어나지 못하는 문제를 해결할 수 있으며, 진행했던 방향만큼 추가적으로 더하여, 관성처럼 빠져나올 수 있게 해준다.\n",
    "\n",
    "<img src=\"./images/momentum.png\" width=\"650px\">\n",
    "\n",
    "#### **AdaGrad (Adaptive Gradient)**\n",
    "- 가중치 별로 서로 다른 학습률을 동적으로 적용한다.\n",
    "- 적게 변화된 가중치는 보다 큰 학습률을 적용하고, 많이 변화된 가중치는 보다 작은 학습률을 적용시킨다.\n",
    "- 처음에는 큰 보폭으로 이동하다가 최소값에 가까워질 수록 작은 보폭으로 이동하게 된다.\n",
    "- 과거의 모든 기울기를 사용하기 때문에 학습률이 급격히 감소하여, 분모가 커짐으로써 학습률이 0에 가까워지는 문제가 있다.\n",
    "\n",
    "\n",
    "<div style=\"display: flex\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./imageadagrad01.pngng\" width=\"1px00\" style=\"margin-top: 20px; margin-left: 10px\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/adagrad02.png\" widthpx=\"400\" style=\"margin-top: 20px; margin-left: 80px\">\r\n",
    "    </div>\r\n",
    "</div>\r\n",
    "\n",
    "\n",
    "#### **RMSProp (Root Mean Sqaure Propagati)**\n",
    "- **AdaGrad의 단점을 보 기법으로서**, 학습률이 지나치게 작아지는 것을 막기 위해  \n",
    "  지수 가중 평균법(exponentially weighted averages)을 통해 구한다.\n",
    "- 지수 가중평균법이란, 데이터의 이동 평균을 구할 때 오래된 데이터가 미치는 영향을 지수적으로 감쇠하도록 하는 방법이다.\n",
    "- 이전의 기울기들을 똑같이 더해가는 것이 아니라 훨씬 이전의 기울기는 조금 반영하고 최근의 기울기를 많이 반영한다.\n",
    "- feature마다 적절한 학습률을 적용하여 효율적인 학습을 진행할 수 있고, AdaGrad보다 학습을 오래할 수 있다.\n",
    "\n",
    "#### **Adam (Adaptive Moment Estimation)**\n",
    "- Momentum과 RMSProp 두 가지 방식을 결합한 형태로서, 진행하던 속도에 관성을 주고, 지수 가중 평균법을 적용한 알고리즘이다.\n",
    "- 최적화 방법에서 가장 많이 사용되는 알고리즘이며, 수식은 아래와 같다.\n",
    "\n",
    "<div style=\"display: flex\">\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/adam01.png\" width=\"300\" style=\"margin-top: 20px; margin-left: 0\">\r\n",
    "    </div>\r\n",
    "    <div>\r\n",
    "        <img src=\"./images/adam02.png\" width=\"200\" style=\"margin-top: 20px; margin-left: 80px\">\r\n",
    "    </div>\r\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ecc57-2030-4dc4-9650-a41e08f85e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거보다 제일 최근에 가중치를 더 부여하는 것 : 지수 가중 평균법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c026141-3a77-49c2-9b53-a62ec8026b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f392d1-c104-419b-a1e1-426e8e41a6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e9756-90f1-40c6-9d28-270e299f702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98997637-a398-4b6d-af67-72b6a4eb4e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
